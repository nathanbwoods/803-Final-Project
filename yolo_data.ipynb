{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "A = pd.read_csv(\"data/A.csv\").values\n",
    "import numpy as np\n",
    "\n",
    "x = np.array(A[:, 0:3].astype(np.float32))\n",
    "x = np.hstack([x, np.ones([len(x[:, 0]), 1])])\n",
    "\n",
    "y = np.array(A[:, 3:5].astype(np.float32))\n",
    "from homography import Transformer\n",
    "\n",
    "t = Transformer()\n",
    "t.fit_homography(x, y)\n",
    "import pickle\n",
    "\n",
    "with open('./transformer.pickle', 'wb') as f:\n",
    "    pickle.dump(t, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "A = pd.read_csv(\"data/units_6100_gt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "camera = A.loc[A['name']=='Camera']\n",
    "c_x, c_y = float(camera['pos.x']), float(camera['pos.y'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "A.drop(A[A['name']=='Camera'].index, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "A['pos.x'] -= c_x\n",
    "A['pos.y'] -= c_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from homography import Transformer\n",
    "import pickle\n",
    "\n",
    "with open(\"./transformer.pickle\", 'rb') as f:\n",
    "    t = pickle.load(f)\n",
    "\n",
    "uv = t.homography_transform(A[['pos.x', 'pos.y', 'pos.z']].values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "A['u'] = uv[:, 0]\n",
    "A['v'] = uv[:, 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "A['w'] = A['radius']*t.x_scale\n",
    "A['h'] = A['radius']*t.y_scale"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "yolo_data = A[['unit_type', 'u', 'v', 'w', 'h']].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pybboxes as pbx\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"data/tick_6100.png\")\n",
    "\n",
    "for box in yolo_data.tolist():\n",
    "    b = pbx.YoloBoundingBox(box[1], box[2], box[3], box[4], (t.image_size, t.image_size))\n",
    "    b = pbx.convert_bbox(b, to_type=\"voc\")\n",
    "    cv2.rectangle(img, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 1)\n",
    "\n",
    "\n",
    "cv2.imwrite(\"tick_6100_boxes.png\", img)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
